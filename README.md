# hed-dlg-truncated
Hierarchical Encoder Decoder RNN (HRED) with Truncated Backpropagation Through Time (Truncated BPTT) for Dialog Modeling. 

The truncated computation is based on the trick of splitting each document into shorter sequences (e.g. 80 tokens) and then computing gradients for each sequence separately, but where the hidden state of the RNNs have been initialized from the preceding sequences (i.e. the hidden states have been forward propagated through the previous states).

# Creating A Dataset

The script convert-text2dict.py can be used to generate model datasets based on text files with dialogues. It only requires that the document contains end-of-utterance tokens &lt;/s&gt; which are used to construct the model graph, since the utterance encoder is only connected to the dialogue encoder at the end of each utterance.

Prepare your dataset as a text file for with one document (e.g. movie script or subtitle) per line. The dialogues are assumed to be tokenized. If you have validation and test sets, they must satisfy the same requirements.

Once you're ready, you can create the model dataset files by running:

python convert-text2dict.py &lt;training_file&gt; --cutoff &lt;vocabulary_size&gt; Training
python convert-text2dict.py &lt;validation_file&gt; --dict=Training.dict.pkl Validation
python convert-text2dict.py &lt;test_file&gt; --dict=Training.dict.pkl &lt;vocabulary_size&gt; Test

where &lt;training_file&gt;, &lt;validation_file&gt; and &lt;test_file&gt; are the training, validation and test files, and &lt;vocabulary_size&gt; is the number of tokens that you want to train on (all other tokens, but the most frequent &lt;vocabulary_size&gt; tokens, will be converted to &lt;unk&gt; symbols).

NOTE: The script automatically adds the following special tokens specific to movie scripts:
- end-of-utterance: &lt;/s&gt;
- end-of-dialogue: &lt;/d&gt;
- first speaker: &lt;first_speaker&gt;
- second speaker: &lt;second_speaker&gt;
- third speaker: &lt;third_speaker&gt;
- minor speaker: &lt;minor_speaker&gt;
- voice over: &lt;voice_over&gt;
- off screen: &lt;off_screen&gt;
- pause: &lt;pause&gt;

If these do not exist in your dataset, you can safely ignore these, but remember that your vocabulary will still contain these.

# Training The Model

If you have Theano with GPU installed (bleeding edge version), you can train the model as follows:
1) Clone the Github repository
2) Create a new "Output" and "Data" directories inside it.
3) Unpack your dataset files into "Data" directory.
4) Create a new prototype inside state.py (look at prototype_movies or prototype_test as examples)
5) From the terminal, cd into the code directory and run:

THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python train.py --prototype &lt;prototype_name&gt; &&gt; Model_Output.txt

For a 7M word dataset, such as the Movie-Scriptolog dataset without any pretraining, this takes about 24 hours to reach convergence.

To test the model afterwards, you can run:

THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python evaluate.py --exclude-sos --plot-graphs Output/&lt;model_name&gt; --document_ids Data/Test_Shuffled_Dataset_Labels.txt &&gt; Model_Evaluation.txt

where &lt;model_name&gt; is the name automatically generated by train.py.

If your GPU runs out of memory, you can adjust the bs (batch size) parameter inside the state.py, but training will be slower. You can also play around with the other parameters inside state.py.
